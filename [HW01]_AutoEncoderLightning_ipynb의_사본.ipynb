{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaeJoowon/KookminUv_Joowon/blob/master/%5BHW01%5D_AutoEncoderLightning_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📝 과제 제출 정보  \n",
        "\n",
        "| 📌 항목  | ✏️ 입력 |\n",
        "|---------|-------|\n",
        "| **학과** | `소프트웨어학과` |\n",
        "| **학번** | `20203149` |\n",
        "| **이름** | `채주원` |\n",
        "\n",
        "🚨 위 과제 제출 정보를 정확히 기입하지 않으면 감점됩니다."
      ],
      "metadata": {
        "id": "58GCUz8-o-Sa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## [HW01] AutoEncoderLightning\n",
        "\n",
        "\n",
        "`[HW01] Autoencoder`에서 진행한 내용을 [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/)을 이용해 재구현하도록 한다.\n",
        "\n",
        "- PyTorch Lightning은 반복적인 코드를 줄이고, 더 깔끔하고 구조화된 방식으로 딥러닝 모델을 개발할 수 있도록 도와주는 프레임워크이다.\n",
        "- 사용 방법은 [여기](https://lightning.ai/docs/pytorch/stable/starter/introduction.html)를 참고하도록 하자.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-_aeV4lfqEzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Lightning 설치"
      ],
      "metadata": {
        "id": "DAZCzDNKrKHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "6l6QMYI7rNFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18882b0-ae86-4335-8351-cec34c5890e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.6.0+cu124)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.14)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
            "Downloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-2.5.1 lightning-utilities-0.14.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1 torchmetrics-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요한 모듈 임포트"
      ],
      "metadata": {
        "id": "M-L0_kH-qfcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch                                      # 파이토치 임포트\n",
        "import torch.nn as nn                             # nn 모듈 임포트\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision                                # torchvision 임포트\n",
        "import torchvision.utils as utils\n",
        "import torchvision.transforms as transforms       # numpy 이미지에서 tensor 이미지로 변경하기 위한 모듈\n",
        "import torchvision.datasets as datasets           # pytorch에 내장된 dataset을 불러오기 위한 모듈\n",
        "\n",
        "import lightning as L                             # PyTorch Ligthning 모듈 임포트\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Numpy:\", np.__version__)\n",
        "\n",
        "print(\"Torch: \", torch.__version__)               # 파이토치 버전을 확인하도록 한다.\n",
        "print(\"Torchvision: \", torchvision.__version__)   # 토치비전 버전을 확인하도록 한다."
      ],
      "metadata": {
        "id": "4vEgz7DjpN46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b879269-6e1b-48c6-efde-a9a80809a4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "Numpy: 2.0.2\n",
            "Torch:  2.6.0+cu124\n",
            "Torchvision:  0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter 설정\n",
        "* batch size, learning rate, epoch을 설정\n",
        "* 잠재 벡터(latent vector) $z$의 크기 설정"
      ],
      "metadata": {
        "id": "YoD4j6wWtQ-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size    = 100\n",
        "learning_rate = 0.001\n",
        "num_epochs    = 10\n",
        "n_dim = 2"
      ],
      "metadata": {
        "id": "fOy6U0rXtSGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋"
      ],
      "metadata": {
        "id": "MC13dP3Ku7yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "# download path 정의\n",
        "download_root = './MNIST_DATASET'\n",
        "\n",
        "\n",
        "# PIL image (H x W x C) -> torch tensor (C x H x W) and\n",
        "# [0, 255] -> [0.0, 1.0]\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(download_root,\n",
        "                      transform=mnist_transform,\n",
        "                      train=True,\n",
        "                      download=True)\n",
        "\n",
        "test_dataset = MNIST(download_root,\n",
        "                     transform=mnist_transform,\n",
        "                     train=False,\n",
        "                     download=False)"
      ],
      "metadata": {
        "id": "yE1QV6N2u-Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fd652f1-9687-44f2-8195-552e56e257b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 476kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.94MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST DataLoader 정의\n",
        "\n",
        "[파이토치 데이터로더](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)는 데이터셋을 배치단위로 묶어 순회(iteration)할 수 있도록 한다.\n",
        "\n",
        "아래 코드는 데이터셋에 대한 데이터로더를 만들고, 각 배치가 어떤 텐서 형태로 구성되어 있는지 확인하는 코드이다.\n",
        "* 데이터로더에서는 이미지들이 배치단위로 묶였기 때문에, B x C x H x W 모양(shape)의 텐서이며, 데이터타입(dtype)은 `torch.float32`가 되었음을 확인하자.\n",
        "* 데이터로더에서는 레이블들이 배치단위로 묶였기 때문에, B 모양(shape)의 텐서이며, 데이터타입(dtype)은 `torch.int64`가 되었음을 확인하자.\n",
        "\n",
        "train_dataset과 test_dataset은 동일 형태이므로, train_dataset의 데이터로더에 대해서만 확인하였다.\n"
      ],
      "metadata": {
        "id": "oybKVTENWUj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# dataloader 정의\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=False)"
      ],
      "metadata": {
        "id": "QBTZdpT5WSqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 네트워크 모델 설계\n",
        "* 인코더 모델: `torch.nn.Sequential` 모듈로 모델로 설계\n",
        "  + InputLayer로 (1,28,28) 영상을 받고, Linear 레이어를 여럿 통과시킨 후, 출력으로 n_dim차원 벡터가 나오도록 함.\n",
        "* 디코더 모델: `torch.nn.Sequential` 모듈로 모델로 설계\n",
        "  + InputLayer에서 n_dim차원 벡터를 받고, Linear 레이어를 여럿 통과시킨 후, 출력으로 (1,28,28) 영상이 나오도록 함.\n",
        "* 오토인코더 모델: 인코더, 디코더를 결합하여 설계\n",
        "\n",
        "### 인코더 모델 정의\n",
        "* (1, 28, 28) 영상을 입력으로 받도록 입력 레이어 정의\n",
        "* Flatten으로 입력 텐서를 784-vector로 벡터라이즈\n",
        "* Fully connected layer로 784 > 256 > 128 > 32 > n_dim 로 차원 축소\n",
        "\n",
        "### 디코더 모델 정의\n",
        "* Fully connected layey로 n_dim > 32 > 128 > 256 > 784로 차원 확대\n",
        "* 784-vector를 Reshape을 통해 (28, 28)의 텐서로 변환"
      ],
      "metadata": {
        "id": "W0TzVysyuwcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc = nn.Sequential(\n",
        "  nn.Flatten(),    # 784 = 1 x 28 x 28\n",
        "  nn.Linear(784, 256),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(256, 128),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(128, 32),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(32, n_dim)\n",
        ")\n",
        "\n",
        "dec = nn.Sequential(\n",
        "    nn.Linear(n_dim, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 784),\n",
        "    nn.Unflatten(1, torch.Size([1, 28, 28])),\n",
        "    nn.Sigmoid(),\n",
        ")"
      ],
      "metadata": {
        "id": "LUWUPPnKsqa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Lightning을 사용한 모델 정의\n",
        "\n",
        "- `LightningModule`을 서브클래싱한 AutoEncoder 클래스를 정의하자.\n",
        "-  `AutoEncoder` 클래스 내부에 학습 루프, 최적화 설정 등을 모두 캡슐화하여 구현\n",
        "\n"
      ],
      "metadata": {
        "id": "lH-Xbl08xEvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "class AutoEncoder(L.LightningModule):\n",
        "  def __init__(self, enc, dec):\n",
        "    super().__init__()\n",
        "    self.enc = enc\n",
        "    self.dec = dec\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    ## training step은 훈련 단계의 각 step에서 진행하는 일을 정의함.\n",
        "    pass\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    pass\n",
        "\n",
        "  def forward(self, x):\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "TacvfFPH0EJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 인스턴스 정의\n",
        "- `AutoEncoder` 클래스의 인스턴스 `ae`를 정의한다.\n",
        "- 모델 인스턴스 `ae`가 어떤 디바이스에 있는지 조사한다."
      ],
      "metadata": {
        "id": "3awozklY-mig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init the autoencoder\n",
        "ae = AutoEncoder(enc, dec)\n",
        "\n",
        "print(ae.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOiqqqOd-97x",
        "outputId": "b159b1ed-31f6-4f09-ea38-c1ebaa0b1f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 네트워크 모델 구조 확인\n",
        "딥러닝 모델의 입출력 구조를 다음과 같이 확인한다.  여기서 중요한 사항은 다음을 확인하는 것이다.\n",
        "\n",
        "1. 레이어의 연결구조,  \n",
        "2. 레이어별 입출력 텐서의 차원,\n",
        "3. 학습할 파라메터 개수\n",
        "\n",
        "* Lightning이 모델을 어떤 디바이스에 보유하고 있는지 `device=str(ae.device)`로 확인하면서 사용해야 함."
      ],
      "metadata": {
        "id": "_K44rYrn1ipC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "qIqREtSZZekL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d066e239-8f3c-4bf6-d2ea-e1777fb246b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(ae, (1, 28, 28), device=str(ae.device))"
      ],
      "metadata": {
        "id": "yYOxN4eTXxm5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "439ffe5e-aea7-48dd-bc2d-2abd74f52f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'numpy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-050cb51864e6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtotal_input_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mtotal_output_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_output\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# x2 for gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mtotal_params_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_params_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtotal_output_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtotal_input_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lightning 모듈에서 지원하는 summarize() 함수로 모델의 구조를 텍스트로 프린트할 수 있음.\n",
        "* 모델이 어떤 디바이스에 있는지 신경쓸 필요 없음.\n",
        "* 하지만 torchsummary 보다 간단한 방식으로만 확인 가능함."
      ],
      "metadata": {
        "id": "AFL8j1ElZfqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.utilities.model_summary import summarize\n",
        "\n",
        "print(summarize(ae, max_depth=2))  # 요약 출력"
      ],
      "metadata": {
        "id": "XXmq7d503QaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 전, 네트워크 모델을 함수로서 활용\n",
        "* AutoEncoder ae를 모델로 구성했기 때문에, 지금부터 함수로서 활용 가능\n",
        "  + 단, ae 함수는 batch 단위로 수행됨을 명심할 것.  \n",
        "    - 단순히, (1, 28, 28) -> ae -> (1, 28, 28)로 동작하지 않고,\n",
        "    - batch 단위로 (?, 1, 28, 28) -> ae -> (?, 1, 28, 28)로 병렬처리됨.\n",
        "* 지금은 훈련 전 네트웍이기 때문에 함수로서는 작동하지만 노이즈 출력만 나올 뿐, 정상적인 출력이 나오는 함수로 동작하지 않음."
      ],
      "metadata": {
        "id": "wYeXbPUsuhCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n"
      ],
      "metadata": {
        "id": "aG8Ot7ZNbDBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 딥러닝 모델 학습\n",
        "\n",
        "Lightning의 `Trainer`를 만들고, `fit()` 함수를 통해 딥러닝 모델을 학습시킴."
      ],
      "metadata": {
        "id": "AaaBD-YOvdoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n"
      ],
      "metadata": {
        "id": "TTeS2Gh8vhJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 트레이닝셋을 이용해 학습 후 결과 시각화\n",
        "학습이 끝난 autoencoder에 대해 train_dataset에 대한 결과 시각화"
      ],
      "metadata": {
        "id": "Tld9oewhvSDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n"
      ],
      "metadata": {
        "id": "p4Cr1m1rvL5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 인코더 / 디코더 모델을 각각 따로 함수로서 활용하기\n",
        "오토인코더 네트웍 전체가 아닌 `enc()` 부분과 `dec()` 부분을 각각 수행할 수 있다.\n",
        "* 특정 예제에 대한 인코딩 결과와 디코딩 결과를 따로 확인한다."
      ],
      "metadata": {
        "id": "XSmbapAxvlGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n"
      ],
      "metadata": {
        "id": "SHeONFLKvYs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "인코딩 결과와 유사한 좌표값을 디코딩에 보내도 유사한 결과가 나옴을 확인"
      ],
      "metadata": {
        "id": "JjKms2oWvxUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n"
      ],
      "metadata": {
        "id": "n8aQKM4MvyCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO\n",
        "1. encoder를 거쳐 나온 representation z를 GT label 별로 다른색을 주어 z의 분포를 가시화한다.\n",
        "2. z의 분포를 보고 encoder가 label 별로 discriminative한 representation을 만들어내는지 여부를 확인한다.\n",
        "3. 만일 discriminative하지 않다면, autoencoder가 discriminative한 representation z를 학습하도록 z의 차원을 바꿔가면서 실험을 진행한다.\n",
        "4. 결과에 대한 분석을 작성한다.\n",
        "\n",
        "## 인코딩 결과 가시화\n",
        "오토인코더의 encoder가 만들어 내는 representation인 z 값을 가시화 한다."
      ],
      "metadata": {
        "id": "M6YoHHcywLqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n"
      ],
      "metadata": {
        "id": "Mja-hYNdvzII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: 디코더를 이용한 Generative Model 구성\n",
        "1. z 공간의 임의의 위치를 sampling한 후, 이를 decoder의 입력으로 주는 방식으로 generative model을 구축한다.\n",
        "2. 결과로 만들어지는 이미지는 어떤 특징을 가지고 있는지 분석한다."
      ],
      "metadata": {
        "id": "hWQmjUDpwhjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO\n"
      ],
      "metadata": {
        "id": "aPqh5f8TwlMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 가시화"
      ],
      "metadata": {
        "id": "rIkun0TvwjYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO\n"
      ],
      "metadata": {
        "id": "1Pb9lmNlwo7W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}